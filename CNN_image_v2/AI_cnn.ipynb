{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZD-Wxzs_7igM",
    "outputId": "caec421e-a90f-414d-9f59-dccfb6d51644"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import genfromtxt\n",
    "import matplotlib.pyplot as plt\n",
    "#!pip install mplfinance\n",
    "import mplfinance as mpf\n",
    "from mplfinance.original_flavor import candlestick2_ochl, candlestick_ohlc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "import keras\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Conv2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#!pip install opencv-python\n",
    "import cv2\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "data = \"data2\"\n",
    "train = data + \"/train/\"\n",
    "validation=  data + \"/validation/\"\n",
    "buy = \"buy/\"\n",
    "sell = \"sell/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(os.listdir(train+buy)) + len(os.listdir(train+sell))\n",
    "\n",
    "# get image dimensions\n",
    "img_path = os.listdir(data + \"/train/buy\")[10]\n",
    "im = cv2.imread(data + \"/train/buy/\" + img_path)\n",
    "\n",
    "# create arrays\n",
    "buy_array = np.empty((len(os.listdir(train+buy)), im.shape[0], im.shape[1], 3))\n",
    "sell_array = np.empty((len(os.listdir(train+sell)), im.shape[0], im.shape[1], 3))\n",
    "\n",
    "\n",
    "# fill buy array\n",
    "files = os.listdir(train + buy)\n",
    "for i, f in enumerate(files):\n",
    "    if f.endswith(\".png\"):\n",
    "        im = cv2.imread(\"data2/train/buy/\" + f)\n",
    "        buy_array[i] = keras.preprocessing.image.img_to_array(im)\n",
    "buy_array /= 255\n",
    "        \n",
    "# fill sell array\n",
    "files = os.listdir(train + sell)\n",
    "for i, f in enumerate(files):\n",
    "    if f.endswith(\".png\"):\n",
    "        im = cv2.imread(\"data2/train/sell/\" + f)\n",
    "        sell_array[i] = keras.preprocessing.image.img_to_array(im)\n",
    "sell_array /= 255\n",
    "\n",
    "\n",
    "# combine and shuffle arrays\n",
    "x_train = np.append(buy_array, sell_array, axis=0)\n",
    "y_train = np.append(np.ones(len(buy_array)), np.zeros(len(sell_array)))\n",
    "p = np.random.permutation(len(x_train))\n",
    "x_train = x_train[p]\n",
    "y_train = y_train[p]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "abE6fhcr7igU",
    "outputId": "1f1318af-a09e-41f2-9821-cb2a299f9385"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_107 (Conv2D)          (None, 140, 144, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 140, 144, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_107 (MaxPoolin (None, 70, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_131 (Dropout)        (None, 70, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_108 (Conv2D)          (None, 70, 72, 64)        8256      \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 70, 72, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_108 (MaxPoolin (None, 35, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_132 (Dropout)        (None, 35, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_109 (Conv2D)          (None, 35, 36, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 35, 36, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_109 (MaxPoolin (None, 17, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_133 (Dropout)        (None, 17, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_30 (Flatten)         (None, 39168)             0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 256)               10027264  \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_134 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 10,241,601\n",
      "Trainable params: 10,241,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_width = im.shape[0]\n",
    "img_height = im.shape[1]\n",
    "\n",
    "\n",
    "# Enter the number of samples, training + validation\n",
    "nb_filters1 = 32\n",
    "nb_filters2 = 64\n",
    "nb_filters3 = 128\n",
    "conv1_size = 3\n",
    "conv2_size = 2\n",
    "conv3_size = 5\n",
    "pool_size = 2\n",
    "# We have 2 classes, buy and sell\n",
    "classes_num = 2\n",
    "batch_size = 128\n",
    "chanDim = 3\n",
    "\n",
    "\n",
    "\n",
    "### custom model\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(nb_filters1, conv1_size, padding ='same', input_shape=(img_width, img_height , 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "model.add(Dropout(0.75))\n",
    "\n",
    "model.add(Convolution2D(nb_filters2, conv2_size, padding =\"same\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size), data_format='channels_last'))\n",
    "model.add(Dropout(0.75))\n",
    "\n",
    "model.add(Convolution2D(nb_filters3, conv3_size, padding ='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size), data_format='channels_last'))\n",
    "model.add(Dropout(0.75))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                      optimizer=optimizers.Adam(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "callbacks_list = [\n",
    "    #OneCycle(min_lr=7e-6, max_lr=7e-2, min_mtm = 0.85, max_mtm = 0.95, annealing_stage=0.1, annealing_rate=0.01, training_iterations=np.ceil(((183*epochs)/(batch_size)))),\n",
    "    #keras.callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_loss\" ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_sLxVPsMpm6e",
    "outputId": "33e50056-a006-490a-db69-99ee1ebe8a09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8509 samples, validate on 2128 samples\n",
      "Epoch 1/500\n",
      "1664/8509 [====>.........................] - ETA: 1:42 - loss: 0.9803 - acc: 0.4928"
     ]
    }
   ],
   "source": [
    "# original - 95% training - 50% validation - overfitting\n",
    "# added 0.75 dropout after each moxpooling and changed from image_generator to numpy array - \n",
    "history = model.fit(x_train, y_train, epochs=500, verbose=1, batch_size=128, shuffle=True, callbacks=callbacks_list, validation_split=0.2)\n",
    "\n",
    "model.save(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K8fbJxr5pm6k",
    "outputId": "22fbbfe1-ccde-48bd-cc8b-a3268495e26c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "test_data_dir = \"data/test\"\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    horizontal_flip=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    #shuffle=True,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FSuhGYaZpm6s"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "AI_cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
