{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZD-Wxzs_7igM",
    "outputId": "caec421e-a90f-414d-9f59-dccfb6d51644"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import genfromtxt\n",
    "import matplotlib.pyplot as plt\n",
    "#!pip install mplfinance\n",
    "import mplfinance as mpf\n",
    "from mplfinance.original_flavor import candlestick2_ochl, candlestick_ohlc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "import keras\n",
    "\n",
    "#!pip install opencv-python\n",
    "import cv2\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "data = \"data2\"\n",
    "train = data + \"/train/\"\n",
    "validation=  data + \"/validation/\"\n",
    "buy = \"buy/\"\n",
    "sell = \"sell/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dqz2Gakfpm6J"
   },
   "outputs": [],
   "source": [
    "### move x% of files to validation folder\n",
    "\n",
    "val_pct = 0.2\n",
    "\n",
    "for i in [buy, sell]:\n",
    "    files = os.listdir(train + i)\n",
    "    \n",
    "    # get index of only candles where signal occurs, a randome sample that is equal to number of buy/sell signals divided by 2 to keep a balance in trianing set:\n",
    "    np.random.seed(42)\n",
    "    files_to_move = np.random.choice(files, replace=False, size=round(len(files)*val_pct))\n",
    "\n",
    "    #files_to_move = files[:round(len(files)*val_pct)]\n",
    "    \n",
    "    if not os.path.exists(validation+i):\n",
    "        os.makedirs(validation+i)\n",
    "    for f in files_to_move:\n",
    "        shutil.move(train + i + f,validation + i) #change move to copy if you want to copy insted of moving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1838.png'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data + \"/train/buy\")[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "abE6fhcr7igU",
    "outputId": "1f1318af-a09e-41f2-9821-cb2a299f9385"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 144, 140, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 144, 140, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 72, 70, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 72, 70, 32)        4128      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 72, 70, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 36, 35, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 36, 35, 64)        8256      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 36, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 18, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 19584)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              20055040  \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 22,169,570\n",
      "Trainable params: 22,169,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Found 8349 images belonging to 2 classes.\n",
      "Found 2087 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# If you like to speed up training process with GPU, first install PlaidML and then uncomment the following line.\n",
    "# Otherwise it will fallback to tensorflow.\n",
    "\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Conv2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "DEV = True\n",
    "argvs = sys.argv\n",
    "argc = len(argvs)\n",
    "\n",
    "if argc > 1 and (argvs[1] == \"--development\" or argvs[1] == \"-d\"):\n",
    "  DEV = True\n",
    "\n",
    "if DEV:\n",
    "  epochs = 10\n",
    "else:\n",
    "  epochs = 1000\n",
    "\n",
    "# BEFORE STARTING TRAINING YOU NEED TO MANUALLY TAKE 20 PERCENENT OF THE TRAINING DATA AND PUT IT INTO VALIDATION FOLDER\n",
    "# I was too lazy to do it in the code.\n",
    "\n",
    "train_data_dir = data + \"/train/\"\n",
    "validation_data_dir = data + \"/validation/\"\n",
    "\n",
    "# Input the size of your sample images\n",
    "img_path = os.listdir(data + \"/train/buy\")[10]\n",
    "im = cv2.imread(data + \"/train/buy/\" + img_path)\n",
    "\n",
    "img_width = im.shape[0]\n",
    "img_height = im.shape[1]\n",
    "\n",
    "\n",
    "# Enter the number of samples, training + validation\n",
    "nb_train_samples = len(os.listdir(train+buy)) + len(os.listdir(train+sell))\n",
    "nb_validation_samples = len(os.listdir(validation+buy)) + len(os.listdir(validation+sell))\n",
    "nb_filters1 = 32\n",
    "nb_filters2 = 32\n",
    "nb_filters3 = 64\n",
    "conv1_size = 3\n",
    "conv2_size = 2\n",
    "conv3_size = 2#5\n",
    "pool_size = 2\n",
    "# We have 2 classes, buy and sell\n",
    "classes_num = 2\n",
    "batch_size = 128\n",
    "lr = 0.001\n",
    "chanDim = 3\n",
    "\n",
    "\n",
    "\n",
    "### custom model\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(nb_filters1, conv1_size, padding ='same', input_shape=(img_height, img_width , 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "model.add(Convolution2D(nb_filters2, conv2_size, padding =\"same\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size), data_format='channels_last'))\n",
    "\n",
    "model.add(Convolution2D(nb_filters3, conv3_size, padding ='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size), data_format='channels_last'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Dense(1024))\n",
    "model.add(Dense(1024))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(classes_num, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                      optimizer=optimizers.RMSprop(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    horizontal_flip=False)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    horizontal_flip=False)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    #shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    #shuffle=True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "\n",
    "callbacks_list = [\n",
    "    #OneCycle(min_lr=7e-6, max_lr=7e-2, min_mtm = 0.85, max_mtm = 0.95, annealing_stage=0.1, annealing_rate=0.01, training_iterations=np.ceil(((183*epochs)/(batch_size)))),\n",
    "    #keras.callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_loss\" ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
    "]\n",
    "\n",
    "#checkpoint = ModelCheckpoint(target_dir, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "#callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_sLxVPsMpm6e",
    "outputId": "33e50056-a006-490a-db69-99ee1ebe8a09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "65/65 [==============================] - 71s 1s/step - loss: 0.9033 - acc: 0.5019 - val_loss: 0.6924 - val_acc: 0.5166\n",
      "Epoch 2/100\n",
      "65/65 [==============================] - 70s 1s/step - loss: 0.6933 - acc: 0.5155 - val_loss: 0.6929 - val_acc: 0.5033\n",
      "Epoch 3/100\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.6903 - acc: 0.5520 - val_loss: 0.7095 - val_acc: 0.5158\n",
      "Epoch 4/100\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.6714 - acc: 0.5947 - val_loss: 0.7314 - val_acc: 0.5043\n",
      "Epoch 5/100\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.6389 - acc: 0.6469 - val_loss: 0.7654 - val_acc: 0.4944\n",
      "Epoch 6/100\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.5912 - acc: 0.6783 - val_loss: 0.8316 - val_acc: 0.5033\n",
      "Epoch 7/100\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.5433 - acc: 0.7182 - val_loss: 1.0029 - val_acc: 0.4946\n",
      "Epoch 8/100\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.4650 - acc: 0.7726 - val_loss: 1.4468 - val_acc: 0.4959\n",
      "Epoch 9/100\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.3780 - acc: 0.8271 - val_loss: 1.1453 - val_acc: 0.4773\n",
      "Epoch 10/100\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.3021 - acc: 0.8702 - val_loss: 1.2047 - val_acc: 0.5128\n",
      "Epoch 11/100\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.2273 - acc: 0.9060 - val_loss: 1.5688 - val_acc: 0.4768\n",
      "Epoch 12/100\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.1938 - acc: 0.9240 - val_loss: 2.2784 - val_acc: 0.4913\n",
      "Epoch 13/100\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.1606 - acc: 0.9388 - val_loss: 2.1856 - val_acc: 0.5059\n",
      "Epoch 14/100\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.1462 - acc: 0.9464 - val_loss: 2.0658 - val_acc: 0.4732\n",
      "Epoch 15/100\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.1252 - acc: 0.9537 - val_loss: 2.6189 - val_acc: 0.5003\n",
      "Epoch 16/100\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.1102 - acc: 0.9620 - val_loss: 2.6422 - val_acc: 0.4967\n",
      "Epoch 17/100\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.1128 - acc: 0.9596 - val_loss: 2.5344 - val_acc: 0.4890\n",
      "Epoch 18/100\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0952 - acc: 0.9656 - val_loss: 2.2970 - val_acc: 0.4915\n",
      "Epoch 19/100\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0914 - acc: 0.9688 - val_loss: 2.4018 - val_acc: 0.5008\n",
      "Epoch 20/100\n",
      "65/65 [==============================] - 67s 1s/step - loss: 0.0728 - acc: 0.9734 - val_loss: 3.1142 - val_acc: 0.4916\n",
      "Epoch 21/100\n",
      "14/65 [=====>........................] - ETA: 52s - loss: 0.0645 - acc: 0.9766"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3ce8cf650667>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m training_history = model.fit_generator(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_train_samples\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1403\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \"\"\"\n\u001b[0;32m-> 1405\u001b[0;31m         return training_generator.fit_generator(\n\u001b[0m\u001b[1;32m   1406\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                 outs = model.train_on_batch(x, y,\n\u001b[0m\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                                             class_weight=class_weight)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/plaidml/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/plaidml/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/plaidml/__init__.py\u001b[0m in \u001b[0;36mas_ndarray\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m   1279\u001b[0m             self._ndarray = np.ndarray(tuple(dim.size for dim in self.shape.dimensions),\n\u001b[1;32m   1280\u001b[0m                                        dtype=_NP_TYPES[self.shape.dtype])\n\u001b[0;32m-> 1281\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmmap_current\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1282\u001b[0m             \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_to_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/plaidml/__init__.py\u001b[0m in \u001b[0;36mmmap_current\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1262\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmmap_current\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m         mapping = _lib().plaidml_map_buffer_current(self.buffer,\n\u001b[0m\u001b[1;32m   1265\u001b[0m                                                     ctypes.cast(None, _MAP_BUFFER_FUNCTYPE), None)\n\u001b[1;32m   1266\u001b[0m         yield _View(self.buffer._ctx, mapping, self.shape.dtype, self.shape.ctype,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/plaidml/__init__.py\u001b[0m in \u001b[0;36m_check_err\u001b[0;34m(self, result, func, args)\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaidml_compute_grad_wrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_err\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# original - 95% training - 50% validation - overfitting\n",
    "# added 0.5 dropout after each convolution\n",
    "training_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples//batch_size,\n",
    "    epochs=20,\n",
    "    shuffle=True,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks_list,\n",
    "    validation_steps=nb_validation_samples//batch_size)\n",
    "\n",
    "model.save(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K8fbJxr5pm6k",
    "outputId": "22fbbfe1-ccde-48bd-cc8b-a3268495e26c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "test_data_dir = \"data/test\"\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    horizontal_flip=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    #shuffle=True,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FSuhGYaZpm6s"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "AI_cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
