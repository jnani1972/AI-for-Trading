{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZD-Wxzs_7igM",
    "outputId": "caec421e-a90f-414d-9f59-dccfb6d51644"
   },
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "import matplotlib.pyplot as plt\n",
    "#!pip install mplfinance\n",
    "import mplfinance as mpf\n",
    "from mplfinance.original_flavor import candlestick2_ochl, candlestick_ohlc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#!pip install opencv-python\n",
    "import cv2\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "data = \"data2\"\n",
    "train = data + \"/train/\"\n",
    "validation=  data + \"/validation/\"\n",
    "buy = \"buy/\"\n",
    "sell = \"sell/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dqz2Gakfpm6J"
   },
   "outputs": [],
   "source": [
    "### move x% of files to validation folder\n",
    "\n",
    "val_pct = 0.2\n",
    "\n",
    "for i in [buy, sell]:\n",
    "    files = os.listdir(train + i)\n",
    "    \n",
    "    # get index of only candles where signal occurs, a randome sample that is equal to number of buy/sell signals divided by 2 to keep a balance in trianing set:\n",
    "    np.random.seed(42)\n",
    "    files_to_move = np.random.choice(files, replace=False, size=round(len(files)*val_pct))\n",
    "\n",
    "    #files_to_move = files[:round(len(files)*val_pct)]\n",
    "    \n",
    "    if not os.path.exists(validation+i):\n",
    "        os.makedirs(validation+i)\n",
    "    for f in files_to_move:\n",
    "        shutil.move(train + i + f,validation + i) #change move to copy if you want to copy insted of moving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10012.png'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data + \"/train/buy\")[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "abE6fhcr7igU",
    "outputId": "1f1318af-a09e-41f2-9821-cb2a299f9385"
   },
   "outputs": [],
   "source": [
    "# If you like to speed up training process with GPU, first install PlaidML and then uncomment the following line.\n",
    "# Otherwise it will fallback to tensorflow.\n",
    "\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "DEV = True\n",
    "argvs = sys.argv\n",
    "argc = len(argvs)\n",
    "\n",
    "if argc > 1 and (argvs[1] == \"--development\" or argvs[1] == \"-d\"):\n",
    "  DEV = True\n",
    "\n",
    "if DEV:\n",
    "  epochs = 10\n",
    "else:\n",
    "  epochs = 1000\n",
    "\n",
    "# BEFORE STARTING TRAINING YOU NEED TO MANUALLY TAKE 20 PERCENENT OF THE TRAINING DATA AND PUT IT INTO VALIDATION FOLDER\n",
    "# I was too lazy to do it in the code.\n",
    "\n",
    "train_data_dir = data + \"/train/\"\n",
    "validation_data_dir = data + \"/validation/\"\n",
    "\n",
    "# Input the size of your sample images\n",
    "img_path = os.listdir(data + \"/train/buy\")[10]\n",
    "im = cv2.imread(data + \"/train/buy/\" + img_path)\n",
    "\n",
    "img_width = im.shape[0]\n",
    "img_height = im.shape[1]\n",
    "\n",
    "\n",
    "# Enter the number of samples, training + validation\n",
    "nb_train_samples = len(os.listdir(train+buy)) + len(os.listdir(train+sell))\n",
    "nb_validation_samples = len(os.listdir(validation+buy)) + len(os.listdir(validation+sell))\n",
    "nb_filters1 = 32\n",
    "nb_filters2 = 32\n",
    "nb_filters3 = 64\n",
    "conv1_size = 3\n",
    "conv2_size = 2\n",
    "conv3_size = 2#5\n",
    "pool_size = 2\n",
    "# We have 2 classes, buy and sell\n",
    "classes_num = 2\n",
    "batch_size = 32\n",
    "lr = 0.001\n",
    "chanDim = 3\n",
    "\n",
    "\n",
    "\n",
    "### custom model\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(nb_filters1, conv1_size, conv1_size, padding ='same', input_shape=(img_height, img_width , 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "model.add(Convolution2D(nb_filters2, conv2_size, conv2_size, padding =\"same\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size), data_format='channels_last'))\n",
    "\n",
    "model.add(Convolution2D(nb_filters3, conv3_size, conv3_size, padding ='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size), data_format='channels_last'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Dense(1024))\n",
    "model.add(Dense(1024))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(classes_num, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                      optimizer=optimizers.RMSprop(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    horizontal_flip=False)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    horizontal_flip=False)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    #shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    #shuffle=True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "\"\"\"\n",
    "Tensorboard log\n",
    "\"\"\"\n",
    "#target_dir = \"./models/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "#if not os.path.exists(target_dir):\n",
    "#  os.mkdir(target_dir)\n",
    "#model.save('./models/model.h5')\n",
    "#model.save_weights('./models/weights.h5')\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#callbacks_list = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "callbacks_list = [\n",
    "    #OneCycle(min_lr=7e-6, max_lr=7e-2, min_mtm = 0.85, max_mtm = 0.95, annealing_stage=0.1, annealing_rate=0.01, training_iterations=np.ceil(((183*epochs)/(batch_size)))),\n",
    "    #keras.callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_loss\" ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
    "]\n",
    "\n",
    "#checkpoint = ModelCheckpoint(target_dir, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "#callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_sLxVPsMpm6e",
    "outputId": "33e50056-a006-490a-db69-99ee1ebe8a09"
   },
   "outputs": [],
   "source": [
    "training_history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples//batch_size,\n",
    "    epochs=epochs*10,\n",
    "    shuffle=True,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks_list,\n",
    "    validation_steps=nb_validation_samples//batch_size)\n",
    "\n",
    "model.save(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K8fbJxr5pm6k",
    "outputId": "22fbbfe1-ccde-48bd-cc8b-a3268495e26c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "test_data_dir = \"data/test\"\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    horizontal_flip=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    #shuffle=True,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FSuhGYaZpm6s"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "AI_cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
