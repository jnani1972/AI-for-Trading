{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZD-Wxzs_7igM",
    "outputId": "caec421e-a90f-414d-9f59-dccfb6d51644"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "from numpy import genfromtxt\n",
    "import matplotlib.pyplot as plt\n",
    "#!pip install mplfinance\n",
    "import mplfinance as mpf\n",
    "from mplfinance.original_flavor import candlestick2_ochl, candlestick_ohlc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras_OneCycle import OneCycle\n",
    "\n",
    "#!pip install opencv-python\n",
    "import cv2\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "data = \"data\"\n",
    "train = data + \"/train/\"\n",
    "validation=  data + \"/validation/\"\n",
    "buy = \"buy/\"\n",
    "sell = \"sell/\"\n",
    "hold = \"hold/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dqz2Gakfpm6J"
   },
   "outputs": [],
   "source": [
    "### move x% of files to validation folder\n",
    "\n",
    "val_pct = 0.2\n",
    "\n",
    "for i in [buy, sell, hold]:\n",
    "    files = os.listdir(train + i)\n",
    "    \n",
    "    # get index of only candles where signal occurs, a randome sample that is equal to number of buy/sell signals divided by 2 to keep a balance in trianing set:\n",
    "    np.random.seed(42)\n",
    "    files_to_move = np.random.choice(files, replace=False, size=round(len(files)*val_pct))\n",
    "\n",
    "    #files_to_move = files[:round(len(files)*val_pct)]\n",
    "    \n",
    "    if not os.path.exists(validation+i):\n",
    "        os.makedirs(validation+i)\n",
    "    for f in files_to_move:\n",
    "        shutil.move(train + i + f,validation + i) #change move to copy if you want to copy insted of moving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "abE6fhcr7igU",
    "outputId": "1f1318af-a09e-41f2-9821-cb2a299f9385"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_30 (Conv2D)           (None, 120, 117, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 120, 117, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 60, 58, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 30, 29, 32)        4128      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 30, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 15, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 8, 7, 64)          8256      \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 8, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 4, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1024)              787456    \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 2,903,011\n",
      "Trainable params: 2,903,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Found 575 images belonging to 3 classes.\n",
      "Found 139 images belonging to 3 classes.\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 4s 222ms/step - loss: 467.1955 - accuracy: 0.3370 - val_loss: 6.1401 - val_accuracy: 0.3359\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 3s 206ms/step - loss: 13906.2314 - accuracy: 0.3352 - val_loss: 146919.4375 - val_accuracy: 0.3359\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 3s 204ms/step - loss: 10601.7002 - accuracy: 0.3444 - val_loss: 22.6785 - val_accuracy: 0.3438\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 3s 201ms/step - loss: 108.2812 - accuracy: 0.3536 - val_loss: 24.0399 - val_accuracy: 0.3359\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 3s 200ms/step - loss: 103.7684 - accuracy: 0.3610 - val_loss: 24.0385 - val_accuracy: 0.3359\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 3s 202ms/step - loss: 102.9701 - accuracy: 0.3481 - val_loss: 24.9357 - val_accuracy: 0.3203\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 3s 200ms/step - loss: 104.6557 - accuracy: 0.3499 - val_loss: 24.1707 - val_accuracy: 0.3281\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 3s 202ms/step - loss: 118.8399 - accuracy: 0.2818 - val_loss: 24.9470 - val_accuracy: 0.3203\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 3s 205ms/step - loss: 104.5754 - accuracy: 0.3536 - val_loss: 25.1393 - val_accuracy: 0.3281\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 3s 203ms/step - loss: 122.8329 - accuracy: 0.3260 - val_loss: 23.9332 - val_accuracy: 0.3438\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 3s 201ms/step - loss: 105.4119 - accuracy: 0.3131 - val_loss: 24.6453 - val_accuracy: 0.3203\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 4s 206ms/step - loss: 105.6899 - accuracy: 0.3757 - val_loss: 24.2616 - val_accuracy: 0.3438\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 3s 201ms/step - loss: 107.7374 - accuracy: 0.3554 - val_loss: 24.0804 - val_accuracy: 0.3359\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 4s 208ms/step - loss: 102.5908 - accuracy: 0.3297 - val_loss: 24.2104 - val_accuracy: 0.3281\n",
      "Epoch 15/100\n",
      " 9/17 [==============>...............] - ETA: 1s - loss: 108.1884 - accuracy: 0.3031"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-38973aaa4668>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;31m#callbacks_list = [checkpoint]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m training_history = model.fit(\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_train_samples\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# If you like to speed up training process with GPU, first install PlaidML and then uncomment the following line.\n",
    "# Otherwise it will fallback to tensorflow.\n",
    "\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "DEV = True\n",
    "argvs = sys.argv\n",
    "argc = len(argvs)\n",
    "\n",
    "if argc > 1 and (argvs[1] == \"--development\" or argvs[1] == \"-d\"):\n",
    "  DEV = True\n",
    "\n",
    "if DEV:\n",
    "  epochs = 10\n",
    "else:\n",
    "  epochs = 1000\n",
    "\n",
    "# BEFORE STARTING TRAINING YOU NEED TO MANUALLY TAKE 20 PERCENENT OF THE TRAINING DATA AND PUT IT INTO VALIDATION FOLDER\n",
    "# I was too lazy to do it in the code.\n",
    "\n",
    "train_data_dir = data + \"/train/\"\n",
    "validation_data_dir = data + \"/validation/\"\n",
    "\n",
    "# Input the size of your sample images\n",
    "img_path = os.listdir(data + \"/train/buy\")[0]\n",
    "im = cv2.imread(data + \"/train/buy/\" + img_path)\n",
    "\n",
    "img_width = im.shape[0]\n",
    "img_height = im.shape[1]\n",
    "\n",
    "\n",
    "# Enter the number of samples, training + validation\n",
    "nb_train_samples = len(os.listdir(train+buy)) + len(os.listdir(train+sell)) + len(os.listdir(train+\"hold\"))\n",
    "nb_validation_samples = len(os.listdir(validation+buy)) + len(os.listdir(validation+sell)) + len(os.listdir(validation+\"hold\"))\n",
    "nb_filters1 = 32\n",
    "nb_filters2 = 32\n",
    "nb_filters3 = 64\n",
    "conv1_size = 3\n",
    "conv2_size = 2\n",
    "conv3_size = 2#5\n",
    "pool_size = 2\n",
    "# We have 3 classes, buy sell, and hold\n",
    "classes_num = 3\n",
    "batch_size = 32\n",
    "lr = 0.001\n",
    "chanDim =3\n",
    "\n",
    "\n",
    "\n",
    "### custom model\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(nb_filters1, conv1_size, conv1_size, padding ='same', input_shape=(img_height, img_width , 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "model.add(Convolution2D(nb_filters2, conv2_size, conv2_size, padding =\"same\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size), data_format='channels_last'))\n",
    "\n",
    "model.add(Convolution2D(nb_filters3, conv3_size, conv3_size, padding ='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size), data_format='channels_last'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Dense(1024))\n",
    "model.add(Dense(1024))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(classes_num, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=optimizers.RMSprop(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    horizontal_flip=False)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    horizontal_flip=False)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    #shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    #shuffle=True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "\"\"\"\n",
    "Tensorboard log\n",
    "\"\"\"\n",
    "target_dir = \"./models/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "#if not os.path.exists(target_dir):\n",
    "#  os.mkdir(target_dir)\n",
    "model.save('./models/model.h5')\n",
    "model.save_weights('./models/weights.h5')\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#callbacks_list = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "callbacks_list = [\n",
    "    OneCycle(min_lr=7e-6, max_lr=7e-2, min_mtm = 0.85, max_mtm = 0.95, annealing_stage=0.1, annealing_rate=0.01, training_iterations=np.ceil(((183*epochs)/(batch_size)))),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model.h5\", save_best_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=0.0001\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1),\n",
    "]\n",
    "\n",
    "#checkpoint = ModelCheckpoint(target_dir, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "#callbacks_list = [checkpoint]\n",
    "\n",
    "training_history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples//batch_size,\n",
    "    epochs=epochs*10,\n",
    "    shuffle=True,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks_list,\n",
    "    validation_steps=nb_validation_samples//batch_size)\n",
    "\n",
    "model.save(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_sLxVPsMpm6e",
    "outputId": "33e50056-a006-490a-db69-99ee1ebe8a09"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7610f29b5f7a7ad3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7610f29b5f7a7ad3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K8fbJxr5pm6k",
    "outputId": "22fbbfe1-ccde-48bd-cc8b-a3268495e26c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "test_data_dir = \"data/test\"\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    horizontal_flip=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    #shuffle=True,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvr73nYqpm6o",
    "outputId": "99958a33-b028-4108-eaef-74d0e42b052e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-07"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FSuhGYaZpm6s"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "AI_cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
