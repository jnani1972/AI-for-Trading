{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Stock_prediction",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kshptl/AI-for-Trading/blob/main/Stock_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHqIXMZ4-Lpm",
        "outputId": "5173c144-d683-41fd-b5b1-3297ffb4e3cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import os\n",
        "from keras_OneCycle import OneCycle\n",
        "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
        "import keras\n",
        "#import tensorflow as tf\n",
        "#from tensorflow import keras\n",
        "\n",
        "#import tensorflow.keras.models as M\n",
        "#import tensorflow.keras.layers as L\n",
        "#from keras import backend as K\n",
        "#keras.backend\n",
        "\n",
        "#import tensorflow as tf\n",
        "#from tensorflow import keras #<------- use this for tensorflow\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install mplfinance\n",
        "import mplfinance as mpf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import seaborn as sns\n",
        "#!pip install keras_lr_finder\n",
        "from keras_lr_finder import LRFinder"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using plaidml.keras.backend backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mplfinance in /usr/local/lib/python3.6/dist-packages (0.12.7a0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from mplfinance) (1.1.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from mplfinance) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->mplfinance) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas->mplfinance) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->mplfinance) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mplfinance) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mplfinance) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mplfinance) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->mplfinance) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUkCw57H-4JR",
        "outputId": "efee7fe6-8d11-4c6e-eeef-2c147815e7f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cd data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4iUQ4G0-5uh"
      },
      "source": [
        "data = pd.read_csv(\"ND100.M5.csv\", parse_dates=True,  names=[\"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "data = data[[\"close\", \"volume\"]]\n",
        "data['pandas_SMA_10'] = data.iloc[:,0].rolling(window=10).mean()\n",
        "data = data.fillna(0)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eei2OjR_uXIO",
        "outputId": "f0858667-3cab-4b12-fd9c-3ba7f6f694d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "data"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>pandas_SMA_10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7219.0</td>\n",
              "      <td>246</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7221.5</td>\n",
              "      <td>349</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7225.7</td>\n",
              "      <td>280</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7224.9</td>\n",
              "      <td>314</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7219.5</td>\n",
              "      <td>329</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100295</th>\n",
              "      <td>11319.4</td>\n",
              "      <td>1248</td>\n",
              "      <td>11314.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100296</th>\n",
              "      <td>11327.7</td>\n",
              "      <td>1588</td>\n",
              "      <td>11317.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100297</th>\n",
              "      <td>11308.6</td>\n",
              "      <td>1556</td>\n",
              "      <td>11318.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100298</th>\n",
              "      <td>11308.5</td>\n",
              "      <td>1734</td>\n",
              "      <td>11319.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100299</th>\n",
              "      <td>11322.9</td>\n",
              "      <td>1082</td>\n",
              "      <td>11321.19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100300 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          close  volume  pandas_SMA_10\n",
              "0        7219.0     246           0.00\n",
              "1        7221.5     349           0.00\n",
              "2        7225.7     280           0.00\n",
              "3        7224.9     314           0.00\n",
              "4        7219.5     329           0.00\n",
              "...         ...     ...            ...\n",
              "100295  11319.4    1248       11314.98\n",
              "100296  11327.7    1588       11317.01\n",
              "100297  11308.6    1556       11318.05\n",
              "100298  11308.5    1734       11319.30\n",
              "100299  11322.9    1082       11321.19\n",
              "\n",
              "[100300 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29EBu2FZvfCm"
      },
      "source": [
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1, predict_forward=3, column=3):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-look_back-predict_forward):\n",
        "        j = i + look_back\n",
        "        a = dataset[i:j,:]\n",
        "        dataX.append(a)\n",
        "\t\t\n",
        "        # for predicting actual price\n",
        "        dataY.append(dataset[j:j + predict_forward, column])\n",
        "\n",
        "        # for % change\n",
        "        #pct = (-data[i + look_back,3] + data[i + look_back+ predict_forward, 3])/data[i + look_back,3]\n",
        "        #if data[i + look_back,3] == 0:\n",
        "        #\tprint(i,\"zero\")\n",
        "\n",
        "    return np.array(dataX), np.array(dataY)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZMokuuawUXa"
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "normalize_max = data.max().max()//1000 \n",
        "# normalize the dataset\n",
        "x_scaler = MinMaxScaler(feature_range=(0,normalize_max))\n",
        "data = x_scaler.fit_transform(data)\n",
        "\n",
        "# remove values that are 0\n",
        "data = np.delete(data,np.where(data==0)[0],axis=0)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x5NEFJ5-63S"
      },
      "source": [
        "n_bars = 10\n",
        "predict_forward = 1\n",
        "x_train, y_train = create_dataset(data,n_bars, predict_forward=predict_forward, column=0)\n",
        "\n",
        "#remove the last sample one bc it may not have enough  y_train values (if the dataset size doenst evenly divide into the sample size)\n",
        "x_train = x_train[:-predict_forward]\n",
        "y_train = np.stack(y_train[:-predict_forward])"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMjUD-HTZtdo"
      },
      "source": [
        "# scale y_train\n",
        "y_scaler = MinMaxScaler(feature_range=(0,normalize_max))\n",
        "y_train = y_scaler.fit_transform(y_train.reshape(-1,1))"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDkJ8JWtQ7dD",
        "outputId": "dbbc26a2-58bf-4aa5-b807-41f124fd38b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train[100]"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.19736255, 0.0533557 , 6.95665991],\n",
              "       [1.20004121, 0.04932886, 6.95736359],\n",
              "       [1.20416223, 0.05436242, 6.95811547],\n",
              "       [1.20416223, 0.07147651, 6.9587324 ],\n",
              "       [1.20127752, 0.03322148, 6.95886736],\n",
              "       [1.1979807 , 0.03724832, 6.95879988],\n",
              "       [1.1979807 , 0.0352349 , 6.95863601],\n",
              "       [1.19324153, 0.06040268, 6.95855889],\n",
              "       [1.19385968, 0.02516779, 6.95866493],\n",
              "       [1.19695044, 0.05436242, 6.95872276]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys7FvvrX-7_C",
        "outputId": "ddb2bbc5-8acc-4194-8f24-f8cd08b28e79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# define model\n",
        "regularizer = keras.regularizers.l2()\n",
        "def make_model(input_shape):\n",
        "\n",
        "    model = keras.models.Sequential()\n",
        "    #model.add(tf.compat.v1.keras.layers.Conv1D(filters=128, kernel_size=3, padding='same', activation='selu'))\n",
        "    #model.add(keras.layers.MaxPooling1D(pool_size=2))\n",
        "    model.add(keras.layers.GRU(20,input_shape=input_shape, recurrent_regularizer=None, return_sequences=True, recurrent_dropout=0.5, activation=\"relu\"))\n",
        "    model.add(keras.layers.GRU(20,input_shape=input_shape, recurrent_regularizer=None, return_sequences=True, recurrent_dropout=0.5, activation=\"relu\"))\n",
        "    model.add(keras.layers.GRU(20,input_shape=input_shape, recurrent_regularizer=None, return_sequences=True, recurrent_dropout=0.5, activation=\"relu\"))\n",
        "    model.add(keras.layers.GRU(20,input_shape=input_shape, recurrent_regularizer=None, recurrent_dropout=0.5, activation=\"relu\"))\n",
        "    model.add(keras.layers.Dense(1))\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = make_model(input_shape=x_train.shape[1:])\n",
        "#model.build(input_shape=x_train.shape[:])\n",
        "\n",
        "callbacks = [\n",
        "    #OneCycle(min_lr=7e-6, max_lr=7e-2, min_mtm = 0.85, max_mtm = 0.95, annealing_stage=0.1, annealing_rate=0.01, training_iterations=np.ceil(((x_train.shape[0]*epochs)/(batch_size)))),\n",
        "\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_mean_squared_error\", factor=0.5, patience=5, min_lr=0.0001),\n",
        "    keras.callbacks.EarlyStopping(monitor=\"mean_squared_error\", patience=20, verbose=1),\n",
        "]\n",
        "\n",
        "opt = keras.optimizers.Adam()\n",
        "model.compile(optimizer=opt, loss=\"mae\", metrics=[\"mse\"])\n",
        "\n",
        "keras.utils.plot_model(model, show_shapes=True)\n",
        "model.summary()\n",
        "\n",
        "# Calling `save('my_model')` creates a SavedModel folder `my_model`.\n",
        "#model.save(\"my_model\")\n",
        "\n",
        "# It can be used to reconstruct the model identically.\n",
        "#reconstructed_model = keras.models.load_model(\"my_model\")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_30 (GRU)                 (None, 10, 20)            1440      \n",
            "_________________________________________________________________\n",
            "gru_31 (GRU)                 (None, 10, 20)            2460      \n",
            "_________________________________________________________________\n",
            "gru_32 (GRU)                 (None, 10, 20)            2460      \n",
            "_________________________________________________________________\n",
            "gru_33 (GRU)                 (None, 20)                2460      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 8,841\n",
            "Trainable params: 8,841\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfdHh8WN-_OZ",
        "outputId": "b938ad03-3566-4e8b-ed3e-9eeecc7ad8ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# fit model : mse - 4e-4 : valmse - 6e-4 : (2x 10 neurons with dropout0.9, relu activation on both) - 0.5 dropout converges quicker\n",
        "# increased n_bars to 20 and added 10-SMA and added another gru layer (total 3 x 20) -> mae is .10\n",
        "# added another layer (total 4 x 20) -> val_mae is 0.030\n",
        "#model = keras.models.load_model('model')\n",
        "history = model.fit(x_train, y_train, epochs=500, verbose=1, batch_size=128, callbacks=callbacks, validation_split=0.2)\n",
        "model.save('modelsave')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 80207 samples, validate on 20052 samples\n",
            "Epoch 1/500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:plaidml:Analyzing Ops: 3456 of 3627 operations complete\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "80207/80207 [==============================] - 78s 967us/step - loss: 0.3169 - mean_squared_error: 0.7762 - val_loss: 0.0299 - val_mean_squared_error: 0.0023\n",
            "Epoch 2/500\n",
            "80207/80207 [==============================] - 26s 321us/step - loss: 0.0246 - mean_squared_error: 0.0017 - val_loss: 0.0615 - val_mean_squared_error: 0.0045\n",
            "Epoch 3/500\n",
            "80207/80207 [==============================] - 26s 329us/step - loss: 0.0206 - mean_squared_error: 0.0012 - val_loss: 0.0415 - val_mean_squared_error: 0.0026\n",
            "Epoch 4/500\n",
            "80207/80207 [==============================] - 27s 335us/step - loss: 0.0179 - mean_squared_error: 9.0499e-04 - val_loss: 0.0232 - val_mean_squared_error: 0.0012\n",
            "Epoch 5/500\n",
            "80207/80207 [==============================] - 27s 331us/step - loss: 0.0174 - mean_squared_error: 8.0752e-04 - val_loss: 0.0368 - val_mean_squared_error: 0.0024\n",
            "Epoch 6/500\n",
            "80207/80207 [==============================] - 26s 328us/step - loss: 0.0176 - mean_squared_error: 7.4708e-04 - val_loss: 0.0274 - val_mean_squared_error: 0.0018\n",
            "Epoch 7/500\n",
            "80207/80207 [==============================] - 27s 335us/step - loss: 0.0186 - mean_squared_error: 8.1918e-04 - val_loss: 0.0191 - val_mean_squared_error: 9.3938e-04\n",
            "Epoch 8/500\n",
            "80207/80207 [==============================] - 26s 324us/step - loss: 0.0150 - mean_squared_error: 6.1004e-04 - val_loss: 0.0238 - val_mean_squared_error: 0.0020\n",
            "Epoch 9/500\n",
            "80207/80207 [==============================] - 26s 323us/step - loss: 0.0156 - mean_squared_error: 6.0333e-04 - val_loss: 0.0328 - val_mean_squared_error: 0.0016\n",
            "Epoch 10/500\n",
            "80207/80207 [==============================] - 26s 330us/step - loss: 0.0150 - mean_squared_error: 5.7723e-04 - val_loss: 0.0310 - val_mean_squared_error: 0.0015\n",
            "Epoch 11/500\n",
            "80207/80207 [==============================] - 26s 330us/step - loss: 0.0153 - mean_squared_error: 5.8140e-04 - val_loss: 0.0352 - val_mean_squared_error: 0.0017\n",
            "Epoch 12/500\n",
            "80207/80207 [==============================] - 28s 351us/step - loss: 0.0155 - mean_squared_error: 5.8223e-04 - val_loss: 0.0174 - val_mean_squared_error: 7.1249e-04\n",
            "Epoch 13/500\n",
            "80207/80207 [==============================] - 28s 355us/step - loss: 0.0146 - mean_squared_error: 5.4229e-04 - val_loss: 0.0368 - val_mean_squared_error: 0.0018\n",
            "Epoch 14/500\n",
            "80207/80207 [==============================] - 28s 347us/step - loss: 0.0153 - mean_squared_error: 5.6492e-04 - val_loss: 0.0194 - val_mean_squared_error: 7.4651e-04\n",
            "Epoch 15/500\n",
            "80207/80207 [==============================] - 29s 358us/step - loss: 0.0146 - mean_squared_error: 5.3426e-04 - val_loss: 0.0285 - val_mean_squared_error: 0.0012\n",
            "Epoch 16/500\n",
            "80207/80207 [==============================] - 28s 351us/step - loss: 0.0145 - mean_squared_error: 5.3040e-04 - val_loss: 0.0224 - val_mean_squared_error: 9.2015e-04\n",
            "Epoch 17/500\n",
            "80207/80207 [==============================] - 28s 352us/step - loss: 0.0141 - mean_squared_error: 5.1364e-04 - val_loss: 0.0269 - val_mean_squared_error: 0.0011\n",
            "Epoch 18/500\n",
            "80207/80207 [==============================] - 28s 348us/step - loss: 0.0112 - mean_squared_error: 4.2364e-04 - val_loss: 0.0280 - val_mean_squared_error: 0.0012\n",
            "Epoch 19/500\n",
            "80207/80207 [==============================] - 29s 363us/step - loss: 0.0116 - mean_squared_error: 4.3311e-04 - val_loss: 0.0247 - val_mean_squared_error: 9.6738e-04\n",
            "Epoch 20/500\n",
            "80207/80207 [==============================] - 28s 351us/step - loss: 0.0118 - mean_squared_error: 4.3607e-04 - val_loss: 0.0217 - val_mean_squared_error: 8.1864e-04\n",
            "Epoch 21/500\n",
            "80207/80207 [==============================] - 28s 350us/step - loss: 0.0118 - mean_squared_error: 4.3378e-04 - val_loss: 0.0176 - val_mean_squared_error: 6.6202e-04\n",
            "Epoch 22/500\n",
            "80207/80207 [==============================] - 28s 344us/step - loss: 0.0119 - mean_squared_error: 4.3878e-04 - val_loss: 0.0207 - val_mean_squared_error: 7.7230e-04\n",
            "Epoch 23/500\n",
            "80207/80207 [==============================] - 28s 351us/step - loss: 0.0110 - mean_squared_error: 4.1620e-04 - val_loss: 0.0168 - val_mean_squared_error: 6.4946e-04\n",
            "Epoch 24/500\n",
            "80207/80207 [==============================] - 28s 353us/step - loss: 0.0108 - mean_squared_error: 4.1116e-04 - val_loss: 0.0169 - val_mean_squared_error: 6.5304e-04\n",
            "Epoch 25/500\n",
            "80207/80207 [==============================] - 28s 352us/step - loss: 0.0109 - mean_squared_error: 4.1268e-04 - val_loss: 0.0176 - val_mean_squared_error: 6.5998e-04\n",
            "Epoch 26/500\n",
            "80207/80207 [==============================] - 28s 351us/step - loss: 0.0109 - mean_squared_error: 4.1116e-04 - val_loss: 0.0256 - val_mean_squared_error: 0.0011\n",
            "Epoch 27/500\n",
            "80207/80207 [==============================] - 28s 348us/step - loss: 0.0110 - mean_squared_error: 4.1396e-04 - val_loss: 0.0179 - val_mean_squared_error: 6.7558e-04\n",
            "Epoch 28/500\n",
            "80207/80207 [==============================] - 28s 345us/step - loss: 0.0107 - mean_squared_error: 4.0562e-04 - val_loss: 0.0177 - val_mean_squared_error: 6.6386e-04\n",
            "Epoch 29/500\n",
            "80207/80207 [==============================] - 27s 340us/step - loss: 0.0106 - mean_squared_error: 4.0421e-04 - val_loss: 0.0170 - val_mean_squared_error: 6.6360e-04\n",
            "Epoch 30/500\n",
            "80207/80207 [==============================] - 28s 349us/step - loss: 0.0106 - mean_squared_error: 4.0465e-04 - val_loss: 0.0212 - val_mean_squared_error: 8.0069e-04\n",
            "Epoch 31/500\n",
            "80207/80207 [==============================] - 28s 344us/step - loss: 0.0107 - mean_squared_error: 4.0498e-04 - val_loss: 0.0214 - val_mean_squared_error: 8.1048e-04\n",
            "Epoch 32/500\n",
            "80207/80207 [==============================] - 28s 349us/step - loss: 0.0106 - mean_squared_error: 4.0437e-04 - val_loss: 0.0168 - val_mean_squared_error: 6.3768e-04\n",
            "Epoch 33/500\n",
            "80207/80207 [==============================] - 28s 347us/step - loss: 0.0106 - mean_squared_error: 4.0306e-04 - val_loss: 0.0173 - val_mean_squared_error: 6.4927e-04\n",
            "Epoch 34/500\n",
            "80207/80207 [==============================] - 28s 348us/step - loss: 0.0106 - mean_squared_error: 4.0358e-04 - val_loss: 0.0174 - val_mean_squared_error: 6.5503e-04\n",
            "Epoch 35/500\n",
            "80207/80207 [==============================] - 27s 339us/step - loss: 0.0106 - mean_squared_error: 4.0422e-04 - val_loss: 0.0172 - val_mean_squared_error: 6.4640e-04\n",
            "Epoch 36/500\n",
            "80207/80207 [==============================] - 28s 346us/step - loss: 0.0107 - mean_squared_error: 4.0476e-04 - val_loss: 0.0207 - val_mean_squared_error: 7.8668e-04\n",
            "Epoch 37/500\n",
            "80207/80207 [==============================] - 27s 343us/step - loss: 0.0106 - mean_squared_error: 4.0431e-04 - val_loss: 0.0204 - val_mean_squared_error: 7.7892e-04\n",
            "Epoch 38/500\n",
            "80207/80207 [==============================] - 28s 347us/step - loss: 0.0107 - mean_squared_error: 4.0480e-04 - val_loss: 0.0170 - val_mean_squared_error: 6.3956e-04\n",
            "Epoch 39/500\n",
            "80207/80207 [==============================] - 28s 344us/step - loss: 0.0106 - mean_squared_error: 4.0324e-04 - val_loss: 0.0164 - val_mean_squared_error: 6.3059e-04\n",
            "Epoch 40/500\n",
            "80207/80207 [==============================] - 28s 348us/step - loss: 0.0106 - mean_squared_error: 4.0398e-04 - val_loss: 0.0171 - val_mean_squared_error: 6.3945e-04\n",
            "Epoch 41/500\n",
            "80207/80207 [==============================] - 28s 353us/step - loss: 0.0106 - mean_squared_error: 4.0419e-04 - val_loss: 0.0167 - val_mean_squared_error: 6.2742e-04\n",
            "Epoch 42/500\n",
            "80207/80207 [==============================] - 28s 344us/step - loss: 0.0106 - mean_squared_error: 4.0321e-04 - val_loss: 0.0181 - val_mean_squared_error: 6.7452e-04\n",
            "Epoch 43/500\n",
            "80207/80207 [==============================] - 28s 346us/step - loss: 0.0106 - mean_squared_error: 4.0410e-04 - val_loss: 0.0183 - val_mean_squared_error: 6.8548e-04\n",
            "Epoch 44/500\n",
            "80207/80207 [==============================] - 28s 345us/step - loss: 0.0106 - mean_squared_error: 4.0314e-04 - val_loss: 0.0170 - val_mean_squared_error: 6.3891e-04\n",
            "Epoch 45/500\n",
            "80207/80207 [==============================] - 28s 345us/step - loss: 0.0106 - mean_squared_error: 4.0329e-04 - val_loss: 0.0162 - val_mean_squared_error: 6.1939e-04\n",
            "Epoch 46/500\n",
            "80207/80207 [==============================] - 27s 339us/step - loss: 0.0106 - mean_squared_error: 4.0331e-04 - val_loss: 0.0163 - val_mean_squared_error: 6.2017e-04\n",
            "Epoch 47/500\n",
            "80207/80207 [==============================] - 28s 351us/step - loss: 0.0106 - mean_squared_error: 4.0308e-04 - val_loss: 0.0172 - val_mean_squared_error: 6.4473e-04\n",
            "Epoch 48/500\n",
            "80207/80207 [==============================] - 27s 341us/step - loss: 0.0106 - mean_squared_error: 4.0361e-04 - val_loss: 0.0169 - val_mean_squared_error: 6.3437e-04\n",
            "Epoch 49/500\n",
            "80207/80207 [==============================] - 28s 347us/step - loss: 0.0106 - mean_squared_error: 4.0299e-04 - val_loss: 0.0164 - val_mean_squared_error: 6.2265e-04\n",
            "Epoch 50/500\n",
            "80207/80207 [==============================] - 28s 344us/step - loss: 0.0106 - mean_squared_error: 4.0243e-04 - val_loss: 0.0177 - val_mean_squared_error: 6.6503e-04\n",
            "Epoch 51/500\n",
            "80207/80207 [==============================] - 28s 347us/step - loss: 0.0106 - mean_squared_error: 4.0231e-04 - val_loss: 0.0162 - val_mean_squared_error: 6.2285e-04\n",
            "Epoch 52/500\n",
            "80207/80207 [==============================] - 28s 350us/step - loss: 0.0106 - mean_squared_error: 4.0205e-04 - val_loss: 0.0171 - val_mean_squared_error: 6.3929e-04\n",
            "Epoch 53/500\n",
            "80207/80207 [==============================] - 28s 345us/step - loss: 0.0106 - mean_squared_error: 4.0216e-04 - val_loss: 0.0174 - val_mean_squared_error: 6.5367e-04\n",
            "Epoch 54/500\n",
            "80207/80207 [==============================] - 28s 351us/step - loss: 0.0106 - mean_squared_error: 4.0362e-04 - val_loss: 0.0188 - val_mean_squared_error: 7.0436e-04\n",
            "Epoch 55/500\n",
            "80207/80207 [==============================] - 28s 345us/step - loss: 0.0106 - mean_squared_error: 4.0321e-04 - val_loss: 0.0218 - val_mean_squared_error: 8.3284e-04\n",
            "Epoch 56/500\n",
            "80207/80207 [==============================] - 28s 344us/step - loss: 0.0106 - mean_squared_error: 4.0362e-04 - val_loss: 0.0171 - val_mean_squared_error: 6.4924e-04\n",
            "Epoch 57/500\n",
            "80207/80207 [==============================] - 27s 340us/step - loss: 0.0106 - mean_squared_error: 4.0309e-04 - val_loss: 0.0204 - val_mean_squared_error: 7.7737e-04\n",
            "Epoch 58/500\n",
            "80207/80207 [==============================] - 28s 350us/step - loss: 0.0106 - mean_squared_error: 4.0308e-04 - val_loss: 0.0178 - val_mean_squared_error: 6.6278e-04\n",
            "Epoch 59/500\n",
            "80207/80207 [==============================] - 27s 343us/step - loss: 0.0106 - mean_squared_error: 4.0384e-04 - val_loss: 0.0169 - val_mean_squared_error: 6.3902e-04\n",
            "Epoch 60/500\n",
            "80207/80207 [==============================] - 28s 346us/step - loss: 0.0106 - mean_squared_error: 4.0309e-04 - val_loss: 0.0171 - val_mean_squared_error: 6.4144e-04\n",
            "Epoch 61/500\n",
            "80207/80207 [==============================] - 28s 349us/step - loss: 0.0106 - mean_squared_error: 4.0266e-04 - val_loss: 0.0174 - val_mean_squared_error: 6.5003e-04\n",
            "Epoch 62/500\n",
            "80207/80207 [==============================] - 28s 347us/step - loss: 0.0107 - mean_squared_error: 4.0368e-04 - val_loss: 0.0164 - val_mean_squared_error: 6.2117e-04\n",
            "Epoch 63/500\n",
            "80207/80207 [==============================] - 28s 344us/step - loss: 0.0106 - mean_squared_error: 4.0205e-04 - val_loss: 0.0165 - val_mean_squared_error: 6.2341e-04\n",
            "Epoch 64/500\n",
            "80207/80207 [==============================] - 27s 343us/step - loss: 0.0106 - mean_squared_error: 4.0389e-04 - val_loss: 0.0167 - val_mean_squared_error: 6.2817e-04\n",
            "Epoch 65/500\n",
            "80207/80207 [==============================] - 27s 342us/step - loss: 0.0106 - mean_squared_error: 4.0347e-04 - val_loss: 0.0204 - val_mean_squared_error: 7.7884e-04\n",
            "Epoch 66/500\n",
            "80207/80207 [==============================] - 28s 343us/step - loss: 0.0106 - mean_squared_error: 4.0307e-04 - val_loss: 0.0161 - val_mean_squared_error: 6.1741e-04\n",
            "Epoch 67/500\n",
            "80207/80207 [==============================] - 27s 336us/step - loss: 0.0106 - mean_squared_error: 4.0263e-04 - val_loss: 0.0210 - val_mean_squared_error: 7.9842e-04\n",
            "Epoch 68/500\n",
            "80207/80207 [==============================] - 27s 338us/step - loss: 0.0106 - mean_squared_error: 4.0268e-04 - val_loss: 0.0169 - val_mean_squared_error: 6.3700e-04\n",
            "Epoch 69/500\n",
            "80207/80207 [==============================] - 28s 343us/step - loss: 0.0106 - mean_squared_error: 4.0328e-04 - val_loss: 0.0179 - val_mean_squared_error: 6.6529e-04\n",
            "Epoch 70/500\n",
            "80207/80207 [==============================] - 27s 341us/step - loss: 0.0106 - mean_squared_error: 4.0289e-04 - val_loss: 0.0172 - val_mean_squared_error: 6.4830e-04\n",
            "Epoch 71/500\n",
            "80207/80207 [==============================] - 27s 342us/step - loss: 0.0106 - mean_squared_error: 4.0263e-04 - val_loss: 0.0167 - val_mean_squared_error: 6.2990e-04\n",
            "Epoch 72/500\n",
            "80207/80207 [==============================] - 27s 339us/step - loss: 0.0106 - mean_squared_error: 4.0257e-04 - val_loss: 0.0168 - val_mean_squared_error: 6.3317e-04\n",
            "Epoch 73/500\n",
            "80207/80207 [==============================] - 28s 344us/step - loss: 0.0106 - mean_squared_error: 4.0267e-04 - val_loss: 0.0185 - val_mean_squared_error: 6.8970e-04\n",
            "Epoch 74/500\n",
            "80207/80207 [==============================] - 27s 335us/step - loss: 0.0106 - mean_squared_error: 4.0242e-04 - val_loss: 0.0200 - val_mean_squared_error: 7.6099e-04\n",
            "Epoch 75/500\n",
            "80207/80207 [==============================] - 28s 345us/step - loss: 0.0106 - mean_squared_error: 4.0339e-04 - val_loss: 0.0201 - val_mean_squared_error: 7.6050e-04\n",
            "Epoch 76/500\n",
            "80207/80207 [==============================] - 28s 346us/step - loss: 0.0106 - mean_squared_error: 4.0334e-04 - val_loss: 0.0164 - val_mean_squared_error: 6.2608e-04\n",
            "Epoch 77/500\n",
            "80207/80207 [==============================] - 27s 340us/step - loss: 0.0106 - mean_squared_error: 4.0273e-04 - val_loss: 0.0162 - val_mean_squared_error: 6.1501e-04\n",
            "Epoch 78/500\n",
            "80207/80207 [==============================] - 27s 341us/step - loss: 0.0106 - mean_squared_error: 4.0331e-04 - val_loss: 0.0170 - val_mean_squared_error: 6.3829e-04\n",
            "Epoch 79/500\n",
            "80207/80207 [==============================] - 27s 341us/step - loss: 0.0106 - mean_squared_error: 4.0310e-04 - val_loss: 0.0163 - val_mean_squared_error: 6.2038e-04\n",
            "Epoch 80/500\n",
            "80207/80207 [==============================] - 28s 347us/step - loss: 0.0106 - mean_squared_error: 4.0191e-04 - val_loss: 0.0163 - val_mean_squared_error: 6.4379e-04\n",
            "Epoch 81/500\n",
            "80207/80207 [==============================] - 27s 343us/step - loss: 0.0107 - mean_squared_error: 4.0411e-04 - val_loss: 0.0168 - val_mean_squared_error: 6.3528e-04\n",
            "Epoch 82/500\n",
            "80207/80207 [==============================] - 27s 343us/step - loss: 0.0106 - mean_squared_error: 4.0217e-04 - val_loss: 0.0161 - val_mean_squared_error: 6.1270e-04\n",
            "Epoch 83/500\n",
            "80207/80207 [==============================] - 27s 342us/step - loss: 0.0106 - mean_squared_error: 4.0201e-04 - val_loss: 0.0171 - val_mean_squared_error: 6.4473e-04\n",
            "Epoch 84/500\n",
            "80207/80207 [==============================] - 28s 345us/step - loss: 0.0106 - mean_squared_error: 4.0154e-04 - val_loss: 0.0172 - val_mean_squared_error: 6.4634e-04\n",
            "Epoch 85/500\n",
            "80207/80207 [==============================] - 27s 341us/step - loss: 0.0106 - mean_squared_error: 4.0284e-04 - val_loss: 0.0189 - val_mean_squared_error: 6.9859e-04\n",
            "Epoch 86/500\n",
            "80207/80207 [==============================] - 28s 351us/step - loss: 0.0106 - mean_squared_error: 4.0330e-04 - val_loss: 0.0164 - val_mean_squared_error: 6.2700e-04\n",
            "Epoch 87/500\n",
            "80207/80207 [==============================] - 27s 341us/step - loss: 0.0106 - mean_squared_error: 4.0265e-04 - val_loss: 0.0173 - val_mean_squared_error: 6.4636e-04\n",
            "Epoch 88/500\n",
            "80207/80207 [==============================] - 27s 340us/step - loss: 0.0106 - mean_squared_error: 4.0276e-04 - val_loss: 0.0164 - val_mean_squared_error: 6.1957e-04\n",
            "Epoch 89/500\n",
            "80207/80207 [==============================] - 27s 338us/step - loss: 0.0106 - mean_squared_error: 4.0372e-04 - val_loss: 0.0192 - val_mean_squared_error: 7.2665e-04\n",
            "Epoch 90/500\n",
            "80207/80207 [==============================] - 27s 339us/step - loss: 0.0106 - mean_squared_error: 4.0147e-04 - val_loss: 0.0197 - val_mean_squared_error: 7.4328e-04\n",
            "Epoch 91/500\n",
            "80207/80207 [==============================] - 27s 337us/step - loss: 0.0106 - mean_squared_error: 4.0166e-04 - val_loss: 0.0196 - val_mean_squared_error: 7.2691e-04\n",
            "Epoch 92/500\n",
            "80207/80207 [==============================] - 27s 336us/step - loss: 0.0106 - mean_squared_error: 4.0300e-04 - val_loss: 0.0175 - val_mean_squared_error: 6.5742e-04\n",
            "Epoch 93/500\n",
            "80207/80207 [==============================] - 27s 337us/step - loss: 0.0106 - mean_squared_error: 4.0230e-04 - val_loss: 0.0177 - val_mean_squared_error: 6.6460e-04\n",
            "Epoch 94/500\n",
            "80207/80207 [==============================] - 27s 334us/step - loss: 0.0107 - mean_squared_error: 4.0434e-04 - val_loss: 0.0175 - val_mean_squared_error: 6.5802e-04\n",
            "Epoch 95/500\n",
            "80207/80207 [==============================] - 27s 336us/step - loss: 0.0106 - mean_squared_error: 4.0185e-04 - val_loss: 0.0196 - val_mean_squared_error: 7.5658e-04\n",
            "Epoch 96/500\n",
            "80207/80207 [==============================] - 27s 338us/step - loss: 0.0106 - mean_squared_error: 4.0285e-04 - val_loss: 0.0173 - val_mean_squared_error: 6.4658e-04\n",
            "Epoch 97/500\n",
            "80207/80207 [==============================] - 28s 343us/step - loss: 0.0107 - mean_squared_error: 4.0442e-04 - val_loss: 0.0186 - val_mean_squared_error: 6.9484e-04\n",
            "Epoch 98/500\n",
            "80207/80207 [==============================] - 28s 345us/step - loss: 0.0106 - mean_squared_error: 4.0167e-04 - val_loss: 0.0191 - val_mean_squared_error: 7.1344e-04\n",
            "Epoch 99/500\n",
            "80207/80207 [==============================] - 27s 340us/step - loss: 0.0106 - mean_squared_error: 4.0253e-04 - val_loss: 0.0179 - val_mean_squared_error: 6.7939e-04\n",
            "Epoch 100/500\n",
            "80207/80207 [==============================] - 27s 333us/step - loss: 0.0106 - mean_squared_error: 4.0380e-04 - val_loss: 0.0167 - val_mean_squared_error: 6.2745e-04\n",
            "Epoch 101/500\n",
            "80207/80207 [==============================] - 27s 338us/step - loss: 0.0106 - mean_squared_error: 4.0248e-04 - val_loss: 0.0165 - val_mean_squared_error: 6.2352e-04\n",
            "Epoch 102/500\n",
            "80207/80207 [==============================] - 27s 337us/step - loss: 0.0106 - mean_squared_error: 4.0184e-04 - val_loss: 0.0166 - val_mean_squared_error: 6.3067e-04\n",
            "Epoch 103/500\n",
            "80207/80207 [==============================] - 27s 337us/step - loss: 0.0106 - mean_squared_error: 4.0194e-04 - val_loss: 0.0171 - val_mean_squared_error: 6.4678e-04\n",
            "Epoch 104/500\n",
            "80207/80207 [==============================] - 27s 338us/step - loss: 0.0106 - mean_squared_error: 4.0400e-04 - val_loss: 0.0180 - val_mean_squared_error: 6.7770e-04\n",
            "Epoch 105/500\n",
            "80207/80207 [==============================] - 27s 335us/step - loss: 0.0106 - mean_squared_error: 4.0169e-04 - val_loss: 0.0177 - val_mean_squared_error: 6.6157e-04\n",
            "Epoch 106/500\n",
            "80207/80207 [==============================] - 27s 335us/step - loss: 0.0107 - mean_squared_error: 4.0453e-04 - val_loss: 0.0162 - val_mean_squared_error: 6.1554e-04\n",
            "Epoch 107/500\n",
            "80207/80207 [==============================] - 27s 336us/step - loss: 0.0106 - mean_squared_error: 4.0195e-04 - val_loss: 0.0180 - val_mean_squared_error: 6.8430e-04\n",
            "Epoch 108/500\n",
            "80207/80207 [==============================] - 27s 337us/step - loss: 0.0106 - mean_squared_error: 4.0219e-04 - val_loss: 0.0165 - val_mean_squared_error: 6.2323e-04\n",
            "Epoch 109/500\n",
            "80207/80207 [==============================] - 28s 345us/step - loss: 0.0106 - mean_squared_error: 4.0209e-04 - val_loss: 0.0160 - val_mean_squared_error: 6.1435e-04\n",
            "Epoch 110/500\n",
            "80207/80207 [==============================] - 27s 340us/step - loss: 0.0106 - mean_squared_error: 4.0277e-04 - val_loss: 0.0170 - val_mean_squared_error: 6.3724e-04\n",
            "Epoch 00110: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHn8FOYU_Ibd",
        "outputId": "b6509e67-7165-4493-fb2e-e46a6445a710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "# show traning/validation plots\n",
        "metric = \"mse\"\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(history.history[metric])\n",
        "plt.plot(history.history[\"val_\" + metric])\n",
        "plt.title(\"model \" + metric)\n",
        "plt.ylabel(metric, fontsize=\"large\")\n",
        "plt.xlabel(\"epoch\", fontsize=\"large\")\n",
        "plt.legend([\"train\", \"val\"], loc=\"best\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-16e6bf8cd56e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRurV1tNbPaB"
      },
      "source": [
        "y_train[-i].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC56B7b6kh_l"
      },
      "source": [
        "# get latest prediction\n",
        "i = 80\n",
        "x_pred = x_train[-i]\n",
        "prediction = model.predict(x_pred.reshape(1,10,5))\n",
        "y_pred = y_scaler.inverse_transform(prediction)\n",
        "y_actual = y_train[-i]\n",
        "print(\"Prediction: \",y_pred[0][0])\n",
        "print( \"Actual: \", y_actual[0])\n",
        "print(\"MSE: \", (y_actual[0]- y_pred[0][0])**2)\n",
        "\n",
        "# plot latest prediction\n",
        "#plt.plot(np.arange(1,y_pred.shape[1]+1),y_pred[0]);\n",
        "#plt.plot(np.arange(y_pred.shape[1]+1,len(y_actual[0])+1),y_actual[0]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLbiTtQtGui9",
        "outputId": "a6e0dd30-b70c-445a-d216-f284f9a566f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        }
      },
      "source": [
        "# model is a Keras model\n",
        "lr_finder = LRFinder(model)\n",
        "\n",
        "# Train a model with batch size 128 for 5 epochs\n",
        "# with learning rate growing exponentially from 0.0001 to 2\n",
        "lr_finder.find(x_train, y_train, start_lr=1e-1, end_lr=1e-0, batch_size=128, epochs=5)\n",
        "\n",
        "# Plot the loss, ignore 20 batches in the beginning and 5 in the end\n",
        "lr_finder.plot_loss(n_skip_beginning=20, n_skip_end=5)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "100268/100268 [==============================] - 17s 172us/step - loss: 5.0925 - mean_squared_error: 3.4010\n",
            "Epoch 2/5\n",
            " 43776/100268 [============>.................] - ETA: 9s - loss: 0.4790 - mean_squared_error: 0.2314"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgbqHW2zdKee"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X89MjW1e3AW"
      },
      "source": [
        "tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egfbg0ULfD52"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}