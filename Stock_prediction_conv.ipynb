{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kshptl/AI-for-Trading/blob/main/Stock_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fHqIXMZ4-Lpm",
    "outputId": "5173c144-d683-41fd-b5b1-3297ffb4e3cf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os\n",
    "from keras_OneCycle import OneCycle\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "import keras\n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "\n",
    "#import tensorflow.keras.models as M\n",
    "#import tensorflow.keras.layers as L\n",
    "#from keras import backend as K\n",
    "#keras.backend\n",
    "\n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras #<------- use this for tensorflow\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#!pip install mplfinance\n",
    "import mplfinance as mpf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IUkCw57H-4JR",
    "outputId": "efee7fe6-8d11-4c6e-eeef-2c147815e7f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kush/Desktop/DS/inpredo-master/RNN_tabular/AI-for-Trading/data\n"
     ]
    }
   ],
   "source": [
    "cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "G4iUQ4G0-5uh"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ND100.M5.csv\", parse_dates=True,  names=[\"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "\n",
    "# # change timeframe\n",
    "logic = {'open'  : 'first',\n",
    "         'high'  : 'max',\n",
    "         'low'   : 'min',\n",
    "         'close' : 'last',\n",
    "         'volume': 'sum'}\n",
    "offset = pd.offsets.timedelta(days=-6)\n",
    "data = data.resample('1H', loffset=offset).apply(logic)\n",
    "\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data = data[[\"close\", \"open\", \"high\", \"low\"]]\n",
    "data['pandas_SMA_3'] = data.iloc[:,0].rolling(window=3).mean()\n",
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>pandas_SMA_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7224.7</td>\n",
       "      <td>7220.4</td>\n",
       "      <td>7226.6</td>\n",
       "      <td>7216.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7220.0</td>\n",
       "      <td>7224.6</td>\n",
       "      <td>7236.5</td>\n",
       "      <td>7207.2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7218.4</td>\n",
       "      <td>7219.7</td>\n",
       "      <td>7253.9</td>\n",
       "      <td>7209.6</td>\n",
       "      <td>7221.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7186.5</td>\n",
       "      <td>7218.7</td>\n",
       "      <td>7235.2</td>\n",
       "      <td>7175.5</td>\n",
       "      <td>7208.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7196.5</td>\n",
       "      <td>7186.7</td>\n",
       "      <td>7211.0</td>\n",
       "      <td>7180.0</td>\n",
       "      <td>7200.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12577</th>\n",
       "      <td>11211.5</td>\n",
       "      <td>11145.1</td>\n",
       "      <td>11212.7</td>\n",
       "      <td>11114.4</td>\n",
       "      <td>11165.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12578</th>\n",
       "      <td>11345.5</td>\n",
       "      <td>11211.4</td>\n",
       "      <td>11347.5</td>\n",
       "      <td>11208.9</td>\n",
       "      <td>11234.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12579</th>\n",
       "      <td>11307.4</td>\n",
       "      <td>11345.0</td>\n",
       "      <td>11359.1</td>\n",
       "      <td>11298.6</td>\n",
       "      <td>11288.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12580</th>\n",
       "      <td>11308.5</td>\n",
       "      <td>11307.5</td>\n",
       "      <td>11338.9</td>\n",
       "      <td>11286.5</td>\n",
       "      <td>11320.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12581</th>\n",
       "      <td>11322.9</td>\n",
       "      <td>11308.6</td>\n",
       "      <td>11326.4</td>\n",
       "      <td>11306.7</td>\n",
       "      <td>11312.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12582 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         close     open     high      low  pandas_SMA_3\n",
       "0       7224.7   7220.4   7226.6   7216.0      0.000000\n",
       "1       7220.0   7224.6   7236.5   7207.2      0.000000\n",
       "2       7218.4   7219.7   7253.9   7209.6   7221.033333\n",
       "3       7186.5   7218.7   7235.2   7175.5   7208.300000\n",
       "4       7196.5   7186.7   7211.0   7180.0   7200.466667\n",
       "...        ...      ...      ...      ...           ...\n",
       "12577  11211.5  11145.1  11212.7  11114.4  11165.266667\n",
       "12578  11345.5  11211.4  11347.5  11208.9  11234.066667\n",
       "12579  11307.4  11345.0  11359.1  11298.6  11288.133333\n",
       "12580  11308.5  11307.5  11338.9  11286.5  11320.466667\n",
       "12581  11322.9  11308.6  11326.4  11306.7  11312.933333\n",
       "\n",
       "[12582 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "29EBu2FZvfCm"
   },
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1, predict_forward=3, column=3):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-predict_forward):\n",
    "        j = i + look_back\n",
    "        a = dataset[i:j,:]\n",
    "        dataX.append(a)\n",
    "\t\t\n",
    "        # for predicting actual price\n",
    "        #dataY.append(dataset[j:j + predict_forward, column])\n",
    "\n",
    "        # for % change\n",
    "        #pct = (-data[i + look_back,3] + data[i + look_back+ predict_forward, 3])/data[i + look_back,3]\n",
    "        #if data[i + look_back,3] == 0:\n",
    "        #\tprint(i,\"zero\")\n",
    "\n",
    "        # for direction\n",
    "        if dataset[j,0] >= dataset[j-1,0]:\n",
    "            dataY.append(1)\n",
    "        else:\n",
    "            dataY.append(0)\n",
    "\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "WZMokuuawUXa"
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "normalize_max = 1\n",
    "# normalize the dataset\n",
    "x_scaler = MinMaxScaler(feature_range=(0,normalize_max))\n",
    "data = x_scaler.fit_transform(data)\n",
    "\n",
    "# remove values that are 0\n",
    "data = np.delete(data,np.where(data==0)[0],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "7x5NEFJ5-63S"
   },
   "outputs": [],
   "source": [
    "n_bars = 100\n",
    "predict_forward = 1\n",
    "x_train, y_train = create_dataset(data,n_bars, predict_forward=predict_forward, column=0)\n",
    "#x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],1) #add the channel at the end\n",
    "\n",
    "#remove the last sample one bc it may not have enough  y_train values (if the dataset size doenst evenly divide into the sample size)\n",
    "x_train = x_train[:-predict_forward]\n",
    "y_train = np.stack(y_train[:-predict_forward])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "PMjUD-HTZtdo"
   },
   "outputs": [],
   "source": [
    "# scale y_train\n",
    "y_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "y_train = y_scaler.fit_transform(y_train.reshape(-1,1))\n",
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.], dtype=float32), array([7606, 7606]))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ys7FvvrX-7_C",
    "outputId": "ddb2bbc5-8acc-4194-8f24-f8cd08b28e79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_47 (Dense)             (7606, 100, 400)          2400      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (7606, 100, 800)          320800    \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (7606, 100, 1200)         961200    \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (7606, 120000)            0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (7606, 2)                 240002    \n",
      "=================================================================\n",
      "Total params: 1,524,402\n",
      "Trainable params: 1,524,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "regularizer = keras.regularizers.l2()\n",
    "def make_model(input_shape):\n",
    "\n",
    "#     model = keras.models.Sequential()\n",
    "#     model.add(keras.layers.Conv1D(32, input_shape=input_shape, kernel_size=5, padding=\"same\", activation=\"relu\"))\n",
    "#     model.add(keras.layers.MaxPool1D(3))\n",
    "#     model.add(keras.layers.Flatten())\n",
    "#     model.add(keras.layers.Dense(2, activation=\"sigmoid\"))\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(400, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(800, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1200, activation=\"relu\"))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(2, activation=\"sigmoid\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = make_model(input_shape=x_train.shape[1:])\n",
    "model.build(input_shape=x_train.shape[:])\n",
    "\n",
    "callbacks = [\n",
    "    #OneCycle(min_lr=7e-6, max_lr=7e-2, min_mtm = 0.85, max_mtm = 0.95, annealing_stage=0.1, annealing_rate=0.01, training_iterations=np.ceil(((x_train.shape[0]*epochs)/(batch_size)))),\n",
    "\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_acc\", factor=0.5, patience=5, min_lr=0.0001),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=20, verbose=1),\n",
    "]\n",
    "\n",
    "opt = keras.optimizers.SGD(lr=1e-6)\n",
    "model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "keras.utils.plot_model(model, show_shapes=True)\n",
    "model.summary()\n",
    "\n",
    "# Calling `save('my_model')` creates a SavedModel folder `my_model`.\n",
    "#model.save(\"my_model\")\n",
    "\n",
    "# It can be used to reconstruct the model identically.\n",
    "#reconstructed_model = keras.models.load_model(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TfdHh8WN-_OZ",
    "outputId": "b938ad03-3566-4e8b-ed3e-9eeecc7ad8ba",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6084 samples, validate on 1522 samples\n",
      "Epoch 1/500\n",
      "6084/6084 [==============================] - 6s 999us/step - loss: 0.6927 - acc: 0.5361 - val_loss: 0.6913 - val_acc: 0.5558\n",
      "Epoch 2/500\n",
      "6084/6084 [==============================] - 3s 554us/step - loss: 0.6927 - acc: 0.5361 - val_loss: 0.6913 - val_acc: 0.5558\n",
      "Epoch 3/500\n",
      "6084/6084 [==============================] - 3s 556us/step - loss: 0.6927 - acc: 0.5361 - val_loss: 0.6913 - val_acc: 0.5558\n",
      "Epoch 4/500\n",
      "6084/6084 [==============================] - 3s 560us/step - loss: 0.6927 - acc: 0.5361 - val_loss: 0.6913 - val_acc: 0.5558\n",
      "Epoch 5/500\n",
      "6084/6084 [==============================] - 3s 559us/step - loss: 0.6927 - acc: 0.5361 - val_loss: 0.6913 - val_acc: 0.5558\n",
      "Epoch 6/500\n",
      "6084/6084 [==============================] - 3s 559us/step - loss: 0.6927 - acc: 0.5360 - val_loss: 0.6913 - val_acc: 0.5558\n",
      "Epoch 7/500\n",
      "6084/6084 [==============================] - 3s 560us/step - loss: 0.6927 - acc: 0.5360 - val_loss: 0.6913 - val_acc: 0.5558\n",
      "Epoch 8/500\n",
      "6084/6084 [==============================] - 3s 561us/step - loss: 0.6927 - acc: 0.5360 - val_loss: 0.6913 - val_acc: 0.5558\n",
      "Epoch 9/500\n",
      "6084/6084 [==============================] - 3s 561us/step - loss: 0.6927 - acc: 0.5360 - val_loss: 0.6913 - val_acc: 0.5558\n",
      "Epoch 10/500\n",
      "6084/6084 [==============================] - 3s 562us/step - loss: 0.6927 - acc: 0.5360 - val_loss: 0.6913 - val_acc: 0.5558\n",
      "Epoch 11/500\n",
      "6084/6084 [==============================] - 3s 563us/step - loss: 0.6927 - acc: 0.5360 - val_loss: 0.6913 - val_acc: 0.5558\n",
      "Epoch 12/500\n",
      "6084/6084 [==============================] - 3s 567us/step - loss: 0.6927 - acc: 0.5360 - val_loss: 0.6913 - val_acc: 0.5558\n",
      "Epoch 13/500\n",
      "6084/6084 [==============================] - 3s 564us/step - loss: 0.6927 - acc: 0.5360 - val_loss: 0.6913 - val_acc: 0.5558\n",
      "Epoch 14/500\n",
      " 896/6084 [===>..........................] - ETA: 2s - loss: 0.6925 - acc: 0.5301"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-c77f43875848>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# added another layer (total 4 x 20) -> val_mae is 0.030\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#model = keras.models.load_model('model')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'modelsave'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m         \u001b[0;31m# Delegate logic to `fit_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m         return training_arrays.fit_loop(self, f, ins,\n\u001b[0m\u001b[1;32m   1028\u001b[0m                                         \u001b[0mout_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m                                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/plaidml/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/plaidml/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/plaidml/__init__.py\u001b[0m in \u001b[0;36mas_ndarray\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m   1279\u001b[0m             self._ndarray = np.ndarray(tuple(dim.size for dim in self.shape.dimensions),\n\u001b[1;32m   1280\u001b[0m                                        dtype=_NP_TYPES[self.shape.dtype])\n\u001b[0;32m-> 1281\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmmap_current\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1282\u001b[0m             \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_to_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/plaidml/__init__.py\u001b[0m in \u001b[0;36mmmap_current\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1262\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmmap_current\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m         mapping = _lib().plaidml_map_buffer_current(self.buffer,\n\u001b[0m\u001b[1;32m   1265\u001b[0m                                                     ctypes.cast(None, _MAP_BUFFER_FUNCTYPE), None)\n\u001b[1;32m   1266\u001b[0m         yield _View(self.buffer._ctx, mapping, self.shape.dtype, self.shape.ctype,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/plaidml/__init__.py\u001b[0m in \u001b[0;36m_check_err\u001b[0;34m(self, result, func, args)\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaidml_compute_grad_wrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_err\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit model : mse - 4e-4 : valmse - 6e-4 : (2x 10 neurons with dropout0.9, relu activation on both) - 0.5 dropout converges quicker\n",
    "# increased n_bars to 20 and added 10-SMA and added another gru layer (total 3 x 20) -> mae is .10\n",
    "# added another layer (total 4 x 20) -> val_mae is 0.030\n",
    "#model = keras.models.load_model('model')\n",
    "history = model.fit(x_train, y_train, epochs=500, verbose=1, batch_size=128, callbacks=callbacks, validation_split=0.2)\n",
    "model.save('modelsave')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "id": "HHn8FOYU_Ibd",
    "outputId": "b6509e67-7165-4493-fb2e-e46a6445a710"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show traning/validation plots\n",
    "metric = \"acc\"\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(history.history[metric])\n",
    "plt.plot(history.history[\"val_\" + metric])\n",
    "plt.title(\"model \" + metric)\n",
    "plt.ylabel(metric, fontsize=\"large\")\n",
    "plt.xlabel(\"epoch\", fontsize=\"large\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"best\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YRurV1tNbPaB"
   },
   "outputs": [],
   "source": [
    "y_train[-i].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iC56B7b6kh_l"
   },
   "outputs": [],
   "source": [
    "# get latest prediction\n",
    "i = 80\n",
    "x_pred = x_train[-i]\n",
    "prediction = model.predict(x_pred.reshape(1,10,5))\n",
    "y_pred = y_scaler.inverse_transform(prediction)\n",
    "y_actual = y_train[-i]\n",
    "print(\"Prediction: \",y_pred[0][0])\n",
    "print( \"Actual: \", y_actual[0])\n",
    "print(\"MSE: \", (y_actual[0]- y_pred[0][0])**2)\n",
    "\n",
    "# plot latest prediction\n",
    "#plt.plot(np.arange(1,y_pred.shape[1]+1),y_pred[0]);\n",
    "#plt.plot(np.arange(y_pred.shape[1]+1,len(y_actual[0])+1),y_actual[0]);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Stock_prediction",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
